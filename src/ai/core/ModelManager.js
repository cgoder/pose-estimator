/**
 * æ¨¡å‹ç®¡ç†å™¨
 * ç»Ÿä¸€ç®¡ç†æ‰€æœ‰AIæ¨¡å‹çš„åŠ è½½ã€ç¼“å­˜ã€å†…å­˜ç®¡ç†ç­‰åŠŸèƒ½
 */

import { IModelProvider, MODEL_STATUS, MODEL_TYPES, IModelInfo } from '../interfaces/IModelProvider.js';
import { eventBus, EVENTS } from '../../utils/EventBus.js';
import { ErrorHandler } from '../../utils/errorHandling.js';

/**
 * æ¨¡å‹ç®¡ç†å™¨ç±»
 * å®ç°ç»Ÿä¸€çš„æ¨¡å‹ç®¡ç†æ¥å£ï¼Œæ”¯æŒå¤šç§æ¨¡å‹æ¡†æ¶
 */
export class ModelManager extends IModelProvider {
    constructor(options = {}) {
        super();
        
        this.models = new Map(); // å·²åŠ è½½çš„æ¨¡å‹ç¼“å­˜
        this.modelConfigs = new Map(); // æ¨¡å‹é…ç½®ç¼“å­˜
        this.currentModel = null; // å½“å‰ä½¿ç”¨çš„æ¨¡å‹
        this.loadingPromises = new Map(); // æ­£åœ¨åŠ è½½çš„æ¨¡å‹Promise
        
        // é…ç½®é€‰é¡¹
        this.options = {
            maxCacheSize: options.maxCacheSize || 3, // æœ€å¤§ç¼“å­˜æ¨¡å‹æ•°é‡
            enableGPU: options.enableGPU !== false,
            enableCache: options.enableCache !== false,
            preloadModels: options.preloadModels || [],
            modelBasePath: options.modelBasePath || '/models',
            memoryThreshold: options.memoryThreshold || 400 * 1024 * 1024, // 400MB
            ...options
        };
        
        // ç»Ÿè®¡ä¿¡æ¯
        this.stats = {
            modelsLoaded: 0,
            totalLoadTime: 0,
            averageLoadTime: 0,
            cacheHits: 0,
            cacheMisses: 0,
            memoryUsage: 0
        };
        
        // é¢„å®šä¹‰çš„æ¨¡å‹é…ç½®
        this._initModelConfigs();
        
        console.log('ğŸ“¦ æ¨¡å‹ç®¡ç†å™¨å·²åˆ›å»º');
    }
    
    /**
     * åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
     * @returns {Promise<void>}
     */
    async init() {
        try {
            console.log('ğŸš€ æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨...');
            
            // æ£€æŸ¥TensorFlow.jsæ˜¯å¦å¯ç”¨
            if (typeof window === 'undefined' || !window.tf) {
                throw new Error('TensorFlow.jsæœªåŠ è½½æˆ–ä¸å¯ç”¨');
            }
            
            // è®¾ç½®TensorFlow.jsåç«¯
            await this._setupTensorFlowBackend();
            
            // é¢„åŠ è½½æŒ‡å®šçš„æ¨¡å‹
            if (this.options.preloadModels.length > 0) {
                await this._preloadModels();
            }
            
            // ç›‘å¬å†…å­˜ä½¿ç”¨æƒ…å†µ
            this._startMemoryMonitoring();
            
            console.log('âœ… æ¨¡å‹ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ');
            
        } catch (error) {
            console.error('âŒ æ¨¡å‹ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥:', error);
            throw ErrorHandler.createError('ModelManager', `åˆå§‹åŒ–å¤±è´¥: ${error.message}`, error);
        }
    }
    
    /**
     * åŠ è½½æ¨¡å‹
     * @param {string} modelType - æ¨¡å‹ç±»å‹
     * @param {Object} config - æ¨¡å‹é…ç½®
     * @returns {Promise<Object>} åŠ è½½çš„æ¨¡å‹
     */
    async loadModel(modelType, config = {}) {
        try {
            // æ£€æŸ¥æ˜¯å¦å·²åœ¨ç¼“å­˜ä¸­
            if (this.models.has(modelType)) {
                this.stats.cacheHits++;
                console.log(`ğŸ“¦ ä»ç¼“å­˜åŠ è½½æ¨¡å‹: ${modelType}`);
                return this.models.get(modelType);
            }
            
            // æ£€æŸ¥æ˜¯å¦æ­£åœ¨åŠ è½½
            if (this.loadingPromises.has(modelType)) {
                console.log(`â³ ç­‰å¾…æ¨¡å‹åŠ è½½å®Œæˆ: ${modelType}`);
                return await this.loadingPromises.get(modelType);
            }
            
            // å¼€å§‹åŠ è½½æ¨¡å‹
            const loadingPromise = this._loadModelInternal(modelType, config);
            this.loadingPromises.set(modelType, loadingPromise);
            
            try {
                const model = await loadingPromise;
                this.loadingPromises.delete(modelType);
                return model;
            } catch (error) {
                this.loadingPromises.delete(modelType);
                throw error;
            }
            
        } catch (error) {
            console.error(`âŒ æ¨¡å‹åŠ è½½å¤±è´¥: ${modelType}`, error);
            throw ErrorHandler.createError('ModelManager', `æ¨¡å‹åŠ è½½å¤±è´¥: ${modelType}`, error);
        }
    }
    
    /**
     * å¸è½½æ¨¡å‹
     * @param {string} modelType - æ¨¡å‹ç±»å‹
     * @returns {Promise<void>}
     */
    async unloadModel(modelType) {
        try {
            if (!this.models.has(modelType)) {
                console.warn(`âš ï¸ æ¨¡å‹æœªåŠ è½½ï¼Œæ— éœ€å¸è½½: ${modelType}`);
                return;
            }
            
            const model = this.models.get(modelType);
            
            // é‡Šæ”¾æ¨¡å‹å†…å­˜
            if (model && typeof model.dispose === 'function') {
                model.dispose();
            }
            
            // ä»ç¼“å­˜ä¸­ç§»é™¤
            this.models.delete(modelType);
            this.modelConfigs.delete(modelType);
            
            // å¦‚æœæ˜¯å½“å‰æ¨¡å‹ï¼Œæ¸…ç©ºå¼•ç”¨
            if (this.currentModel === modelType) {
                this.currentModel = null;
            }
            
            console.log(`ğŸ—‘ï¸ æ¨¡å‹å·²å¸è½½: ${modelType}`);
            
            // å‘å¸ƒæ¨¡å‹å¸è½½äº‹ä»¶
            eventBus.emit(EVENTS.MODEL_UNLOADED, {
                modelType,
                remainingModels: Array.from(this.models.keys())
            });
            
        } catch (error) {
            console.error(`âŒ æ¨¡å‹å¸è½½å¤±è´¥: ${modelType}`, error);
            throw error;
        }
    }
    
    /**
     * è·å–æ¨¡å‹ä¿¡æ¯
     * @param {string} modelType - æ¨¡å‹ç±»å‹
     * @returns {IModelInfo|null} æ¨¡å‹ä¿¡æ¯
     */
    getModelInfo(modelType) {
        const config = this.modelConfigs.get(modelType);
        if (!config) {
            return null;
        }
        
        const isLoaded = this.models.has(modelType);
        const model = this.models.get(modelType);
        
        return {
            type: modelType,
            status: isLoaded ? MODEL_STATUS.LOADED : MODEL_STATUS.UNLOADED,
            config: { ...config },
            memoryUsage: this._getModelMemoryUsage(model),
            loadTime: config.loadTime || 0,
            lastUsed: config.lastUsed || null,
            isCurrent: this.currentModel === modelType
        };
    }
    
    /**
     * é¢„çƒ­æ¨¡å‹
     * @param {string} modelType - æ¨¡å‹ç±»å‹
     * @param {any} sampleInput - æ ·æœ¬è¾“å…¥æ•°æ®
     * @returns {Promise<void>}
     */
    async warmupModel(modelType, sampleInput = null) {
        try {
            const model = await this.loadModel(modelType);
            
            if (!sampleInput) {
                // ä½¿ç”¨é»˜è®¤æ ·æœ¬æ•°æ®
                sampleInput = this._createSampleInput(modelType);
            }
            
            console.log(`ğŸ”¥ æ­£åœ¨é¢„çƒ­æ¨¡å‹: ${modelType}`);
            
            // æ‰§è¡Œä¸€æ¬¡æ¨ç†æ¥é¢„çƒ­æ¨¡å‹
            const startTime = performance.now();
            await this._runInference(model, sampleInput);
            const warmupTime = performance.now() - startTime;
            
            // æ›´æ–°é…ç½®
            const config = this.modelConfigs.get(modelType);
            if (config) {
                config.warmupTime = warmupTime;
                config.isWarmedUp = true;
            }
            
            console.log(`âœ… æ¨¡å‹é¢„çƒ­å®Œæˆ: ${modelType} (${warmupTime.toFixed(2)}ms)`);
            
        } catch (error) {
            console.error(`âŒ æ¨¡å‹é¢„çƒ­å¤±è´¥: ${modelType}`, error);
            throw error;
        }
    }
    
    /**
     * æ¸…ç†æœªä½¿ç”¨çš„æ¨¡å‹
     * @returns {Promise<void>}
     */
    async cleanupUnusedModels() {
        try {
            const now = Date.now();
            const unusedThreshold = 5 * 60 * 1000; // 5åˆ†é’Ÿæœªä½¿ç”¨
            const modelsToRemove = [];
            
            for (const [modelType, config] of this.modelConfigs.entries()) {
                if (modelType === this.currentModel) {
                    continue; // ä¸æ¸…ç†å½“å‰ä½¿ç”¨çš„æ¨¡å‹
                }
                
                if (config.lastUsed && (now - config.lastUsed) > unusedThreshold) {
                    modelsToRemove.push(modelType);
                }
            }
            
            // æŒ‰æœ€åä½¿ç”¨æ—¶é—´æ’åºï¼Œä¼˜å…ˆæ¸…ç†æœ€ä¹…æœªä½¿ç”¨çš„
            modelsToRemove.sort((a, b) => {
                const configA = this.modelConfigs.get(a);
                const configB = this.modelConfigs.get(b);
                return (configA.lastUsed || 0) - (configB.lastUsed || 0);
            });
            
            // æ¸…ç†æ¨¡å‹
            for (const modelType of modelsToRemove) {
                await this.unloadModel(modelType);
            }
            
            if (modelsToRemove.length > 0) {
                console.log(`ğŸ§¹ å·²æ¸…ç† ${modelsToRemove.length} ä¸ªæœªä½¿ç”¨çš„æ¨¡å‹`);
            }
            
        } catch (error) {
            console.error('âŒ æ¸…ç†æœªä½¿ç”¨æ¨¡å‹å¤±è´¥:', error);
        }
    }
    
    /**
     * è·å–å½“å‰ä½¿ç”¨çš„æ¨¡å‹
     * @returns {string|null} å½“å‰æ¨¡å‹ç±»å‹
     */
    getCurrentModel() {
        return this.currentModel;
    }
    
    /**
     * è®¾ç½®å½“å‰ä½¿ç”¨çš„æ¨¡å‹
     * @param {string} modelType - æ¨¡å‹ç±»å‹
     */
    setCurrentModel(modelType) {
        if (this.models.has(modelType)) {
            this.currentModel = modelType;
            
            // æ›´æ–°æœ€åä½¿ç”¨æ—¶é—´
            const config = this.modelConfigs.get(modelType);
            if (config) {
                config.lastUsed = Date.now();
            }
            
            console.log(`ğŸ¯ å½“å‰æ¨¡å‹è®¾ç½®ä¸º: ${modelType}`);
        } else {
            console.warn(`âš ï¸ æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•è®¾ç½®ä¸ºå½“å‰æ¨¡å‹: ${modelType}`);
        }
    }
    
    /**
     * å¤„ç†è¾“å…¥æ•°æ®
     * @param {any} inputData - è¾“å…¥æ•°æ®
     * @param {Object} options - å¤„ç†é€‰é¡¹
     * @returns {Promise<any>} å¤„ç†ç»“æœ
     */
    async process(inputData, options = {}) {
        try {
            const modelType = options.modelType || this.currentModel;
            if (!modelType) {
                throw new Error('æœªæŒ‡å®šæ¨¡å‹ç±»å‹ä¸”æ— å½“å‰æ¨¡å‹');
            }
            
            const model = await this.loadModel(modelType);
            this.setCurrentModel(modelType);
            
            // æ‰§è¡Œæ¨ç†
            const result = await this._runInference(model, inputData, options);
            
            return result;
            
        } catch (error) {
            console.error('âŒ æ¨¡å‹å¤„ç†å¤±è´¥:', error);
            throw error;
        }
    }
    
    /**
     * è·å–ç®¡ç†å™¨çŠ¶æ€
     * @returns {Object} çŠ¶æ€ä¿¡æ¯
     */
    getStatus() {
        return {
            loadedModels: Array.from(this.models.keys()),
            currentModel: this.currentModel,
            cacheSize: this.models.size,
            maxCacheSize: this.options.maxCacheSize,
            stats: { ...this.stats },
            memoryUsage: this._getTotalMemoryUsage(),
            options: { ...this.options }
        };
    }
    
    /**
     * æ¸…ç†æ‰€æœ‰èµ„æº
     * @returns {Promise<void>}
     */
    async cleanup() {
        try {
            console.log('ğŸ§¹ æ­£åœ¨æ¸…ç†æ¨¡å‹ç®¡ç†å™¨èµ„æº...');
            
            // åœæ­¢å†…å­˜ç›‘æ§
            if (this.memoryMonitorInterval) {
                clearInterval(this.memoryMonitorInterval);
                this.memoryMonitorInterval = null;
            }
            
            // å¸è½½æ‰€æœ‰æ¨¡å‹
            const modelTypes = Array.from(this.models.keys());
            for (const modelType of modelTypes) {
                await this.unloadModel(modelType);
            }
            
            // æ¸…ç©ºç¼“å­˜
            this.models.clear();
            this.modelConfigs.clear();
            this.loadingPromises.clear();
            this.currentModel = null;
            
            console.log('âœ… æ¨¡å‹ç®¡ç†å™¨èµ„æºæ¸…ç†å®Œæˆ');
            
        } catch (error) {
            console.error('âŒ æ¨¡å‹ç®¡ç†å™¨æ¸…ç†å¤±è´¥:', error);
            throw error;
        }
    }
    
    /**
     * å†…éƒ¨æ¨¡å‹åŠ è½½å®ç°
     * @private
     * @param {string} modelType - æ¨¡å‹ç±»å‹
     * @param {Object} config - æ¨¡å‹é…ç½®
     * @returns {Promise<Object>} åŠ è½½çš„æ¨¡å‹
     */
    async _loadModelInternal(modelType, config = {}) {
        const startTime = performance.now();
        
        try {
            // æ£€æŸ¥ç¼“å­˜å¤§å°ï¼Œå¿…è¦æ—¶æ¸…ç†
            await this._ensureCacheSpace();
            
            // è·å–æ¨¡å‹é…ç½®
            const modelConfig = this._getModelConfig(modelType, config);
            
            console.log(`ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹: ${modelType}`);
            
            // æ ¹æ®æ¨¡å‹ç±»å‹åŠ è½½
            let model;
            switch (modelConfig.framework) {
                case 'tensorflow':
                    model = await this._loadTensorFlowModel(modelConfig);
                    break;
                default:
                    throw new Error(`ä¸æ”¯æŒçš„æ¨¡å‹æ¡†æ¶: ${modelConfig.framework}`);
            }
            
            const loadTime = performance.now() - startTime;
            
            // æ›´æ–°é…ç½®
            modelConfig.loadTime = loadTime;
            modelConfig.lastUsed = Date.now();
            modelConfig.status = MODEL_STATUS.LOADED;
            
            // ç¼“å­˜æ¨¡å‹å’Œé…ç½®
            this.models.set(modelType, model);
            this.modelConfigs.set(modelType, modelConfig);
            
            // æ›´æ–°ç»Ÿè®¡
            this.stats.modelsLoaded++;
            this.stats.totalLoadTime += loadTime;
            this.stats.averageLoadTime = this.stats.totalLoadTime / this.stats.modelsLoaded;
            this.stats.cacheMisses++;
            
            console.log(`âœ… æ¨¡å‹åŠ è½½å®Œæˆ: ${modelType} (${loadTime.toFixed(2)}ms)`);
            
            // å‘å¸ƒæ¨¡å‹åŠ è½½äº‹ä»¶
            eventBus.emit(EVENTS.MODEL_LOADED, {
                modelType,
                loadTime,
                memoryUsage: this._getModelMemoryUsage(model)
            });
            
            return model;
            
        } catch (error) {
            console.error(`âŒ æ¨¡å‹åŠ è½½å¤±è´¥: ${modelType}`, error);
            throw error;
        }
    }
    
    /**
     * åŠ è½½TensorFlowæ¨¡å‹
     * @private
     * @param {Object} config - æ¨¡å‹é…ç½®
     * @returns {Promise<Object>} TensorFlowæ¨¡å‹
     */
    async _loadTensorFlowModel(config) {
        const tf = window.tf;
        
        if (!tf) {
            throw new Error('TensorFlow.jsæœªåŠ è½½');
        }
        
        // æ„å»ºæ¨¡å‹URL
        const modelUrl = `${this.options.modelBasePath}/${config.path}/model.json`;
        
        // åŠ è½½æ¨¡å‹
        const model = await tf.loadLayersModel(modelUrl, {
            onProgress: (fraction) => {
                console.log(`ğŸ“¦ æ¨¡å‹åŠ è½½è¿›åº¦: ${(fraction * 100).toFixed(1)}%`);
            }
        });
        
        return model;
    }
    
    /**
     * æ‰§è¡Œæ¨¡å‹æ¨ç†
     * @private
     * @param {Object} model - æ¨¡å‹å®ä¾‹
     * @param {any} inputData - è¾“å…¥æ•°æ®
     * @param {Object} options - æ¨ç†é€‰é¡¹
     * @returns {Promise<any>} æ¨ç†ç»“æœ
     */
    async _runInference(model, inputData, options = {}) {
        const tf = window.tf;
        
        if (!tf || !model) {
            throw new Error('æ¨¡å‹æˆ–TensorFlow.jsä¸å¯ç”¨');
        }
        
        // å°†è¾“å…¥æ•°æ®è½¬æ¢ä¸ºå¼ é‡
        let inputTensor;
        if (inputData instanceof tf.Tensor) {
            inputTensor = inputData;
        } else {
            inputTensor = tf.browser.fromPixels(inputData);
        }
        
        try {
            // æ‰§è¡Œæ¨ç†
            const result = await model.predict(inputTensor);
            return result;
            
        } finally {
            // æ¸…ç†è¾“å…¥å¼ é‡ï¼ˆå¦‚æœæ˜¯æˆ‘ä»¬åˆ›å»ºçš„ï¼‰
            if (!(inputData instanceof tf.Tensor)) {
                inputTensor.dispose();
            }
        }
    }
    
    /**
     * åˆå§‹åŒ–æ¨¡å‹é…ç½®
     * @private
     */
    _initModelConfigs() {
        // PoseNetæ¨¡å‹é…ç½®
        this.modelConfigs.set(MODEL_TYPES.POSENET, {
            type: MODEL_TYPES.POSENET,
            framework: 'tensorflow',
            path: 'posenet',
            inputShape: [1, 513, 513, 3],
            outputShape: [1, 17, 3],
            status: MODEL_STATUS.UNLOADED
        });
        
        // MoveNetæ¨¡å‹é…ç½®
        this.modelConfigs.set(MODEL_TYPES.MOVENET, {
            type: MODEL_TYPES.MOVENET,
            framework: 'tensorflow',
            path: 'movenet',
            inputShape: [1, 256, 256, 3],
            outputShape: [1, 17, 3],
            status: MODEL_STATUS.UNLOADED
        });
    }
    
    /**
     * è·å–æ¨¡å‹é…ç½®
     * @private
     * @param {string} modelType - æ¨¡å‹ç±»å‹
     * @param {Object} customConfig - è‡ªå®šä¹‰é…ç½®
     * @returns {Object} åˆå¹¶åçš„é…ç½®
     */
    _getModelConfig(modelType, customConfig = {}) {
        const defaultConfig = this.modelConfigs.get(modelType);
        if (!defaultConfig) {
            throw new Error(`æœªçŸ¥çš„æ¨¡å‹ç±»å‹: ${modelType}`);
        }
        
        return { ...defaultConfig, ...customConfig };
    }
    
    /**
     * ç¡®ä¿ç¼“å­˜ç©ºé—´
     * @private
     */
    async _ensureCacheSpace() {
        if (this.models.size >= this.options.maxCacheSize) {
            // æ‰¾åˆ°æœ€ä¹…æœªä½¿ç”¨çš„æ¨¡å‹
            let oldestModel = null;
            let oldestTime = Date.now();
            
            for (const [modelType, config] of this.modelConfigs.entries()) {
                if (modelType === this.currentModel) {
                    continue; // ä¸æ¸…ç†å½“å‰æ¨¡å‹
                }
                
                const lastUsed = config.lastUsed || 0;
                if (lastUsed < oldestTime) {
                    oldestTime = lastUsed;
                    oldestModel = modelType;
                }
            }
            
            if (oldestModel) {
                await this.unloadModel(oldestModel);
            }
        }
    }
    
    /**
     * é¢„åŠ è½½æ¨¡å‹
     * @private
     */
    async _preloadModels() {
        for (const modelType of this.options.preloadModels) {
            try {
                await this.loadModel(modelType);
            } catch (error) {
                console.warn(`âš ï¸ é¢„åŠ è½½æ¨¡å‹å¤±è´¥: ${modelType}`, error);
            }
        }
    }
    
    /**
     * è®¾ç½®TensorFlowåç«¯
     * @private
     */
    async _setupTensorFlowBackend() {
        const tf = window.tf;
        
        if (this.options.enableGPU) {
            try {
                await tf.setBackend('webgl');
                console.log('ğŸ® GPUåç«¯å·²å¯ç”¨');
            } catch (error) {
                console.warn('âš ï¸ GPUåç«¯å¯ç”¨å¤±è´¥ï¼Œå›é€€åˆ°CPU:', error);
                await tf.setBackend('cpu');
            }
        } else {
            await tf.setBackend('cpu');
            console.log('ğŸ’» CPUåç«¯å·²å¯ç”¨');
        }
        
        await tf.ready();
    }
    
    /**
     * åˆ›å»ºæ ·æœ¬è¾“å…¥æ•°æ®
     * @private
     * @param {string} modelType - æ¨¡å‹ç±»å‹
     * @returns {any} æ ·æœ¬è¾“å…¥
     */
    _createSampleInput(modelType) {
        const tf = window.tf;
        const config = this.modelConfigs.get(modelType);
        
        if (config && config.inputShape) {
            return tf.zeros(config.inputShape);
        }
        
        // é»˜è®¤æ ·æœ¬è¾“å…¥
        return tf.zeros([1, 256, 256, 3]);
    }
    
    /**
     * è·å–æ¨¡å‹å†…å­˜ä½¿ç”¨é‡
     * @private
     * @param {Object} model - æ¨¡å‹å®ä¾‹
     * @returns {number} å†…å­˜ä½¿ç”¨é‡ï¼ˆå­—èŠ‚ï¼‰
     */
    _getModelMemoryUsage(model) {
        if (!model) return 0;
        
        try {
            // ä¼°ç®—æ¨¡å‹å†…å­˜ä½¿ç”¨é‡
            if (model.countParams) {
                return model.countParams() * 4; // å‡è®¾æ¯ä¸ªå‚æ•°4å­—èŠ‚
            }
        } catch (error) {
            // å¿½ç•¥é”™è¯¯
        }
        
        return 0;
    }
    
    /**
     * è·å–æ€»å†…å­˜ä½¿ç”¨é‡
     * @private
     * @returns {Object} å†…å­˜ä½¿ç”¨ä¿¡æ¯
     */
    _getTotalMemoryUsage() {
        const tf = window.tf;
        if (tf && tf.memory) {
            return tf.memory();
        }
        return { numTensors: 0, numDataBuffers: 0, numBytes: 0 };
    }
    
    /**
     * å¼€å§‹å†…å­˜ç›‘æ§
     * @private
     */
    _startMemoryMonitoring() {
        this.memoryMonitorInterval = setInterval(() => {
            const memoryInfo = this._getTotalMemoryUsage();
            this.stats.memoryUsage = memoryInfo.numBytes;
            
            // æ£€æŸ¥å†…å­˜é˜ˆå€¼
            if (memoryInfo.numBytes > this.options.memoryThreshold) {
                eventBus.emit(EVENTS.MEMORY_WARNING, {
                    current: memoryInfo.numBytes,
                    threshold: this.options.memoryThreshold,
                    source: 'ModelManager'
                });
            }
        }, 10000); // æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡
    }
}

// å¯¼å‡ºæ¨¡å‹ç±»å‹å’ŒçŠ¶æ€æšä¸¾
export { MODEL_STATUS, MODEL_TYPES };